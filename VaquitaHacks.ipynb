{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_exif_data(imagename):\n",
    "    image = Image.open(imagename)\n",
    "    exifdata = image.getexif()\n",
    "    \n",
    "    for tag_id in exifdata:\n",
    "        tag = TAGS.get(tag_id, tag_id)\n",
    "        data = exifdata.get(tag_id) \n",
    "        if isinstance(data, bytes):\n",
    "            data = data.decode()\n",
    "        print(f\"{tag:25}: {data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'X_train is not a file in the archive'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-23ab9d49d3b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnpz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'all_images.npz'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnpz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'X_train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mY_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnpz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Y_train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mnpz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'We have {} examples to work with'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    264\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not a file in the archive\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'X_train is not a file in the archive'"
     ]
    }
   ],
   "source": [
    "npz = np.load('all_images.npz')\n",
    "\n",
    "\n",
    "X_train = npz['X_train']\n",
    "Y_train = npz['Y_train']\n",
    "del npz\n",
    "print ('We have {} examples to work with'.format(Y_train.shape[0]-1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The added layer must be an instance of class Layer. Found: <keras.layers.core.Reshape object at 0x00000265AFCCF088>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-d49778c4570b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m         tf.keras.layers.Flatten()])\n\u001b[0m\u001b[0;32m    157\u001b[0m   \u001b[0mselected_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVGG19\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, layers, name)\u001b[0m\n\u001b[0;32m    114\u001b[0m       \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_no_legacy_layers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    159\u001b[0m       raise TypeError('The added layer must be '\n\u001b[0;32m    160\u001b[0m                       \u001b[1;34m'an instance of class Layer. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m                       'Found: ' + str(layer))\n\u001b[0m\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_no_legacy_layers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: The added layer must be an instance of class Layer. Found: <keras.layers.core.Reshape object at 0x00000265AFCCF088>"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"face_verification_mode;.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1VBowq7FpWtV-55jpZaxvvdeMCbZwRvK_\n",
    "\"\"\"\n",
    "\n",
    "# Mount drive (If you are running from Google Colab).\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "# Imports.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import models, activations, losses, optimizers\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import (Conv2D, MaxPool2D, MaxPooling2D, Dropout, Dense, \n",
    "                          Input, concatenate, GlobalAveragePooling2D, \n",
    "                          AveragePooling2D, Flatten, Lambda, Reshape)\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Inputs\n",
    "\n",
    "# Choose one of the following CNN architectures: 'LeNet5', 'AlexNet', 'VGG19', or 'GoogleNet'\n",
    "cnn_architecture = 'VGG19'  \n",
    "\n",
    "# Directory to the training set images. \n",
    "# The directory must contain one folder per person. Each folder must include 4-5 images of that person.\n",
    "directory = os.getcwd() + 'E:\\vaquitahacks\\People' \n",
    "\n",
    "# Directory to the validation set images. \n",
    "# The directory must include the images that you want to test. It should NOT contain folders. \n",
    "test_directory = os.getcwd() + 'E:\\vaquitahacks\\test_images' \n",
    "\n",
    "# Epochs (iterations) of CNN training in TensorFlow.\n",
    "training_epochs = 50\n",
    "\n",
    "def images_to_list(path, dims) :\n",
    "    \"\"\"\n",
    "    Converts all the images in a given directory to numerical values.\n",
    "\n",
    "    Inputs:\n",
    "      path (str): Directory to the folder that contains the images.\n",
    "      dims (int): Target size of the images (width and height)\n",
    "    Output:\n",
    "      images (list): A list of numpy arrays, each array represinting an image.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    for image_path in os.listdir(path):\n",
    "        image = tf.keras.preprocessing.image.load_img(os.path.join(path, image_path))\n",
    "        image = image.resize((dims, dims))\n",
    "        image = np.swapaxes(np.asarray(image), 0, 1) / 255\n",
    "        images.append(image)\n",
    "    return images\n",
    "\n",
    "def data_pre_processing(path, dims):\n",
    "    \"\"\"\n",
    "    Process the input of the face verification model.\n",
    "\n",
    "    Inputs:\n",
    "      path (str): Directory to the folder containing the face images. The \n",
    "                  directory must contain the face of each person.\n",
    "      dims (int): Target size of the images (width and height)\n",
    "    Output:\n",
    "      CNN Input: Three arrays, containing the faces \n",
    "    \"\"\"\n",
    "    \n",
    "    # Image Pre-processing\n",
    "    images, labels = [], []\n",
    "    for i, person in enumerate(os.listdir(path)):\n",
    "        local_path = os.path.join(path, person)\n",
    "        images += images_to_list(local_path, dims)      \n",
    "        labels += [i]*len(os.listdir(local_path))\n",
    "    images = np.array(images)\n",
    "    \n",
    "    # Combinations and Labels.\n",
    "    array_1 = array_2 = [i for i in range(len(labels))]\n",
    "    mesh = np.array(np.meshgrid(array_1, array_2))\n",
    "    combinations = mesh.T.reshape(-1, 2)\n",
    "    C1, C2 = [images[i[0]] for i in combinations], [images[i[1]] for i in combinations]\n",
    "    Y = np.array([labels[c[0]] == labels[c[1]] for c in combinations]).astype(int)\n",
    "           \n",
    "    # Return.\n",
    "    return C1, C2, Y\n",
    "\n",
    "def list_to_flatten(list_of_images, dims):\n",
    "    images = np.array(list_of_images)\n",
    "    images = images.reshape((images.shape[0], (dims**2)*3)).astype(np.float32)\n",
    "    return images\n",
    "\n",
    "# CNN Models\n",
    "\n",
    "# LeNet5\n",
    "if cnn_architecture == 'LeNet5':\n",
    "  image_dimension = 128\n",
    "  input_shape = ((image_dimension**2) * 3 ,)\n",
    "  LeNet5 = tf.keras.models.Sequential([\n",
    "            Reshape(input_shape=input_shape, target_shape=(image_dimension, image_dimension, 3)),\n",
    "            tf.keras.layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu'),\n",
    "            tf.keras.layers.AveragePooling2D(),\n",
    "            tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'),\n",
    "            tf.keras.layers.AveragePooling2D(),\n",
    "            tf.keras.layers.Flatten()])\n",
    "  selected_model = LeNet5\n",
    "\n",
    "# AlexNet\n",
    "# This implementation was written based on an existing model developed by Eddie Weill, which can be found in the following link:\n",
    "# https://github.com/eweill/keras-deepcv/blob/master/models/classification/alexnet.py \n",
    "elif cnn_architecture == 'AlexNet':\n",
    "  image_dimension = 224\n",
    "  input_shape = ((image_dimension**2) * 3 ,)\n",
    "  AlexNet = tf.keras.models.Sequential([\n",
    "        Reshape(input_shape=input_shape, target_shape=(image_dimension, image_dimension, 3)),\n",
    "        tf.keras.layers.Conv2D(96, (11,11), strides=(4,4), activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "        tf.keras.layers.Conv2D(256, (5,5), activation='relu', padding=\"same\"),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "        tf.keras.layers.Conv2D(384, (3,3), activation='relu', padding=\"same\"),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Conv2D(384, (1,1), activation='relu', padding=\"same\"),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Conv2D(256, (1,1), activation='relu', padding=\"same\"),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "        tf.keras.layers.Flatten()])\n",
    "  selected_model = AlexNet\n",
    "\n",
    "# VGGNet\n",
    "# This implementation was written based on an existing model developed by Taehoon Lee, which can be found in the following link:\n",
    "# https://github.com/keras-team/keras-applications/blob/master/keras_applications/vgg16.py \n",
    "elif cnn_architecture == 'VGG19':\n",
    "  image_dimension = 224\n",
    "  input_shape = ((image_dimension**2) * 3 ,)\n",
    "  VGG19 = tf.keras.models.Sequential([\n",
    "        Reshape(input_shape=input_shape, target_shape=(image_dimension, image_dimension, 3)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "        tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "        tf.keras.layers.Flatten()])\n",
    "  selected_model = VGG19\n",
    "\n",
    "# GoogLeNet (First few layers).\n",
    "elif cnn_architecture == 'GoogleNet':\n",
    "  \"Simplified version of GoogleNet, using only the first few layers of the CNN\"\n",
    "  image_dimension = 224\n",
    "  input_shape = ((image_dimension**2) * 3 ,)\n",
    "  googlenet = tf.keras.models.Sequential([\n",
    "      Reshape(input_shape=input_shape, target_shape=(image_dimension, image_dimension, 3)),\n",
    "      Conv2D(64, (7, 7), padding='same', strides=(2, 2), activation='relu'),\n",
    "      MaxPooling2D((3, 3), padding='same', strides=(2, 2)),\n",
    "      Conv2D(64, (1, 1), padding='same', strides=(1, 1), activation='relu'),\n",
    "      Conv2D(192, (3, 3), padding='same', strides=(1, 1), activation='relu'),\n",
    "      MaxPooling2D((3, 3), padding='same', strides=(2, 2)),\n",
    "      tf.keras.layers.Flatten()])\n",
    "  selected_model = googlenet\n",
    "\n",
    "# CNN model function\n",
    "# This function is based on an existing model developed by Shubham Panchal, which can be found in the following repository:\n",
    "# https://github.com/shubham0204/Face_Recognition_with_TF/blob/master/SiameseModel.py\n",
    "def cnn_model(dims):\n",
    "    input_shape = ((dims**2) * 3 ,)\n",
    "    input_1, input_2 = Input(shape=input_shape), Input(shape=input_shape)\n",
    "    output_1, output_2 = selected_model(input_1), selected_model(input_2)\n",
    "    distance_euclidean = Lambda(lambda t: K.abs(t[0] - t[1]))([output_1 , output_2])\n",
    "    outputs = Dense(1, activation=\"sigmoid\")(distance_euclidean)\n",
    "    return models.Model([input_1, input_2], outputs)\n",
    "\n",
    "# CODE\n",
    "C1, C2, Y = data_pre_processing(directory, image_dimension)\n",
    "C1, C2 = list_to_flatten(C1, image_dimension), list_to_flatten(C2, image_dimension)\n",
    "X = [C1, C2]\n",
    "\n",
    "# Extras (This functions are used for the model training in TensorFlow)\n",
    "checkpoint = ModelCheckpoint('model_' + str(image_dimension) + '.h5', verbose=1, monitor='loss', \n",
    "                              save_best_only=True, mode='auto')\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10**(epoch / 20))\n",
    "\n",
    "# Model training.\n",
    "model = cnn_model(image_dimension)\n",
    "model.compile(loss=losses.binary_crossentropy , optimizer=optimizers.Adam())\n",
    "history = model.fit(X, Y, batch_size=1, epochs=training_epochs, callbacks=[checkpoint, lr_schedule]) \n",
    "model.load_weights('model_' + str(image_dimension) + '.h5')\n",
    "\n",
    "# Plot learning rate vs loss.\n",
    "plt.semilogx(history.history[\"lr\"], history.history[\"loss\"])\n",
    "plt.axis([1e-4, 1e-2, 0., 1])\n",
    "plt.xlabel('Learning rate')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "# Testing.\n",
    "\n",
    "# Array preparation.\n",
    "test_images = images_to_list(test_directory, image_dimension)\n",
    "test_images = list_to_flatten(test_images, image_dimension)\n",
    "   \n",
    "labels = [[e]*len(os.listdir(directory + '/' + i)) for e, i in enumerate(os.listdir(directory))]\n",
    "labels = list(itertools.chain.from_iterable(labels))\n",
    "training_images = C2[:len(labels), :]\n",
    "\n",
    "# Predict.\n",
    "names = ['Angelina', 'Brad']\n",
    "confidences = []\n",
    "for e, tensor in enumerate(test_images, 1):\n",
    "    \n",
    "    # Show image.\n",
    "    plt.imshow(np.rot90(tensor.reshape((image_dimension, image_dimension, 3)), k=-1))\n",
    "    plt.show()\n",
    "    \n",
    "    # Predict scores.\n",
    "    scores = [model.predict([tensor.reshape((1, -1)), sample.reshape((1, -1))])[0]  for sample in training_images]\n",
    "    \n",
    "    # Find the largest score, and its corresponding index.\n",
    "    idx = np.argmax(scores)\n",
    "    label = labels[idx]\n",
    "    name = names[label] \n",
    "    print( 'IMAGE {} is {} with confidence of {}%'.format(e, name, round(100*scores[idx][0], 2)))\n",
    "    confidences.append(scores[idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
